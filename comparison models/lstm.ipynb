{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Date', 'Price']\n",
    "data= pd.read_csv('C:/Users/kship/Desktop/Stock-Market-Prediction/research paper/data.csv', names=column_names)\n",
    "training_data = data[:int(0.8 * len(data))]\n",
    "testing_data = data[int(0.8 * len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kship\\AppData\\Local\\Temp\\ipykernel_17300\\2208127990.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['Price'] = scaler.fit_transform(training_data[['Price']])\n",
      "C:\\Users\\kship\\AppData\\Local\\Temp\\ipykernel_17300\\2208127990.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testing_data['Price'] = scaler.transform(testing_data[['Price']])\n"
     ]
    }
   ],
   "source": [
    "# Create a MinMax scaler to normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "training_data['Price'] = scaler.fit_transform(training_data[['Price']])\n",
    "testing_data['Price'] = scaler.transform(testing_data[['Price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into sequences of X and y values\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(training_data)):\n",
    "    X_train.append(training_data['Price'][i-60:i])\n",
    "    y_train.append(training_data['Price'][i])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "    tf.keras.layers.LSTM(50),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "68/68 [==============================] - 6s 28ms/step - loss: 0.0117\n",
      "Epoch 2/40\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 5.6756e-04\n",
      "Epoch 3/40\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 5.2368e-04\n",
      "Epoch 4/40\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 5.0775e-04\n",
      "Epoch 5/40\n",
      "68/68 [==============================] - 2s 29ms/step - loss: 4.7376e-04\n",
      "Epoch 6/40\n",
      "68/68 [==============================] - 2s 29ms/step - loss: 4.5296e-04\n",
      "Epoch 7/40\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 4.3090e-04\n",
      "Epoch 8/40\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 4.5158e-04\n",
      "Epoch 9/40\n",
      "68/68 [==============================] - 2s 29ms/step - loss: 4.1627e-04\n",
      "Epoch 10/40\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 3.8473e-04\n",
      "Epoch 11/40\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 3.7636e-04\n",
      "Epoch 12/40\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 3.5922e-04\n",
      "Epoch 13/40\n",
      "68/68 [==============================] - 2s 28ms/step - loss: 3.6224e-04\n",
      "Epoch 14/40\n",
      "68/68 [==============================] - 2s 28ms/step - loss: 3.5547e-04\n",
      "Epoch 15/40\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 3.4997e-04\n",
      "Epoch 16/40\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 3.2214e-04\n",
      "Epoch 17/40\n",
      "68/68 [==============================] - 3s 47ms/step - loss: 3.1248e-04\n",
      "Epoch 18/40\n",
      "68/68 [==============================] - 6s 92ms/step - loss: 3.2616e-04\n",
      "Epoch 19/40\n",
      "68/68 [==============================] - 4s 58ms/step - loss: 2.8727e-04\n",
      "Epoch 20/40\n",
      "68/68 [==============================] - 2s 28ms/step - loss: 2.9089e-04\n",
      "Epoch 21/40\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 2.8267e-04\n",
      "Epoch 22/40\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 2.6389e-04\n",
      "Epoch 23/40\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 2.5257e-04\n",
      "Epoch 24/40\n",
      "68/68 [==============================] - 2s 29ms/step - loss: 2.6003e-04\n",
      "Epoch 25/40\n",
      "68/68 [==============================] - 2s 35ms/step - loss: 2.3872e-04\n",
      "Epoch 26/40\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 2.7914e-04\n",
      "Epoch 27/40\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 2.2571e-04\n",
      "Epoch 28/40\n",
      "68/68 [==============================] - 2s 28ms/step - loss: 2.0875e-04\n",
      "Epoch 29/40\n",
      "68/68 [==============================] - 2s 29ms/step - loss: 2.0665e-04\n",
      "Epoch 30/40\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 2.0045e-04\n",
      "Epoch 31/40\n",
      "68/68 [==============================] - 2s 29ms/step - loss: 1.9241e-04\n",
      "Epoch 32/40\n",
      "68/68 [==============================] - 2s 28ms/step - loss: 2.4235e-04\n",
      "Epoch 33/40\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.8107e-04\n",
      "Epoch 34/40\n",
      "68/68 [==============================] - 6s 90ms/step - loss: 1.8954e-04\n",
      "Epoch 35/40\n",
      "68/68 [==============================] - 7s 96ms/step - loss: 1.6780e-04\n",
      "Epoch 36/40\n",
      "68/68 [==============================] - 8s 111ms/step - loss: 1.9155e-04\n",
      "Epoch 37/40\n",
      "68/68 [==============================] - 6s 91ms/step - loss: 1.8479e-04\n",
      "Epoch 38/40\n",
      "68/68 [==============================] - 7s 99ms/step - loss: 1.7069e-04\n",
      "Epoch 39/40\n",
      "68/68 [==============================] - 7s 99ms/step - loss: 1.8473e-04\n",
      "Epoch 40/40\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 1.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22c9cd50810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kship\\AppData\\Local\\Temp\\ipykernel_17300\\3574674923.py:4: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  X_test.append(testing_data['Price'][i-60:i])\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "X_test = []\n",
    "for i in range(60, len(testing_data)):\n",
    "    X_test.append(testing_data['Price'][i-60:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(X_test)\n",
    "predicted_prices = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kship\\Desktop\\Stock-Market-Prediction\\research paper\\lstm.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kship/Desktop/Stock-Market-Prediction/research%20paper/lstm.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Invert the normalization and evaluate the model performance\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kship/Desktop/Stock-Market-Prediction/research%20paper/lstm.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predicted_prices \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(predicted_prices)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kship/Desktop/Stock-Market-Prediction/research%20paper/lstm.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m true_prices \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(true_prices)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kship/Desktop/Stock-Market-Prediction/research%20paper/lstm.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m true_prices \u001b[39m=\u001b[39m testing_data[\u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m60\u001b[39m:]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Invert the normalization and evaluate the model performance\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "true_prices = scaler.inverse_transform(true_prices)\n",
    "true_prices = testing_data['Price'][60:]\n",
    "mse = mean_squared_error(true_prices, predicted_prices)\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
